{"cells":[{"cell_type":"code","execution_count":null,"id":"edaaec95","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54621,"status":"ok","timestamp":1766089523886,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"edaaec95","outputId":"8bb8c923-d092-4d1e-b91e-bed638982ae8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n","Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-25.3\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.1)\n","Collecting langchain-community\n","  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n","Collecting langchain-groq\n","  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.59)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n","Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n","Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n","  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n","Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n","  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n","Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n","  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n","  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n","Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n","Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n","Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n","Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, groq, dataclasses-json, langchain-text-splitters, langchain-groq, langchain-classic, langchain-community\n","\u001b[2K  Attempting uninstall: requests\n","\u001b[2K    Found existing installation: requests 2.32.4\n","\u001b[2K    Uninstalling requests-2.32.4:\n","\u001b[2K      Successfully uninstalled requests-2.32.4\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [langchain-community]\n","\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dataclasses-json-0.6.7 groq-0.37.1 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-groq-1.1.1 langchain-text-splitters-1.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n","Collecting chromadb\n","  Downloading chromadb-1.3.7-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","Collecting build>=1.0.3 (from chromadb)\n","  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n","Collecting pybase64>=1.4.1 (from chromadb)\n","  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n","Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n","  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n","Collecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n","Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.5)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n","Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n","Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.11.12)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n","  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n","Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb)\n","  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n","Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n","Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Downloading chromadb-1.3.7-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n","Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n","Downloading build-1.3.0-py3-none-any.whl (23 kB)\n","Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n","Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n","Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n","Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n","Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n","Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n","Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=e28f97a2161f84ffcfddd189b642d797e7a471a2ad96828fba069d0c4683410a\n","  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pybase64, opentelemetry-proto, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n","\u001b[2K  Attempting uninstall: urllib3\n","\u001b[2K    Found existing installation: urllib3 2.5.0\n","\u001b[2K    Uninstalling urllib3-2.5.0:\n","\u001b[2K      Successfully uninstalled urllib3-2.5.0\n","\u001b[2K  Attempting uninstall: opentelemetry-proto\n","\u001b[2K    Found existing installation: opentelemetry-proto 1.37.0\n","\u001b[2K    Uninstalling opentelemetry-proto-1.37.0:\n","\u001b[2K      Successfully uninstalled opentelemetry-proto-1.37.0\n","\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n","\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n","\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n","\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n","\u001b[2K  Attempting uninstall: opentelemetry-api\n","\u001b[2K    Found existing installation: opentelemetry-api 1.37.0\n","\u001b[2K    Uninstalling opentelemetry-api-1.37.0:\n","\u001b[2K      Successfully uninstalled opentelemetry-api-1.37.0\n","\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions\n","\u001b[2K    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n","\u001b[2K    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n","\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n","\u001b[2K  Attempting uninstall: opentelemetry-sdk\n","\u001b[2K    Found existing installation: opentelemetry-sdk 1.37.0\n","\u001b[2K    Uninstalling opentelemetry-sdk-1.37.0:\n","\u001b[2K      Successfully uninstalled opentelemetry-sdk-1.37.0\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [chromadb]\n","\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n","google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n","google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.7 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (4.15.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n"]}],"source":["# Upgrade pip to avoid dependency resolution issues\n","!pip install --upgrade pip\n","\n","# Core utilities\n","!pip install python-dotenv tqdm\n","\n","# LangChain modular packages (post-0.1.x architecture)\n","!pip install \\\n","    langchain-core \\\n","    langchain-community \\\n","    langchain-groq\n","\n","# Vector store backend\n","!pip install chromadb\n","\n","# Embeddings dependencies\n","!pip install sentence-transformers huggingface-hub\n","\n","# Optional but commonly required by Chroma + LangChain\n","!pip install pydantic typing-extensions\n"]},{"cell_type":"code","execution_count":1,"id":"200ceae4","metadata":{"executionInfo":{"elapsed":25,"status":"error","timestamp":1766167000481,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"200ceae4","colab":{"base_uri":"https://localhost:8080/","height":547},"outputId":"6a5a72b3-8e24-4ac9-8644-9b5e17af3bf1"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'langchain_groq'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1222044887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_groq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGroq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_groq'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv()\n","\n","import json\n","from tqdm import tqdm\n","from langchain_groq import ChatGroq\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import Chroma\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableLambda\n","from operator import itemgetter"]},{"cell_type":"code","execution_count":null,"id":"gjkRsDFkW-nc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21045,"status":"ok","timestamp":1766089572063,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"gjkRsDFkW-nc","outputId":"2deefe26-88ba-4aa0-9b16-f1e4ac1f1a0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"SQ1bZNvLY2Bc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144,"status":"ok","timestamp":1766089574805,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"SQ1bZNvLY2Bc","outputId":"ca8c87f7-31b2-4df7-cde3-44e01b23aaf1"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Agentic-RAG-Chatbot  'Colab Notebooks'   Colab_Notebooks   extra\n"]}],"source":["!ls /content/drive/MyDrive\n"]},{"cell_type":"code","execution_count":null,"id":"YZZuTImcbBRm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1766089578381,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"YZZuTImcbBRm","outputId":"42076159-03bf-471c-b13b-3236b12e0e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Agentic-RAG-Chatbot\n"]}],"source":["%cd \"/content/drive/MyDrive/Agentic-RAG-Chatbot\"\n"]},{"cell_type":"code","execution_count":null,"id":"fiPot09kbIWF","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1766089579925,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"fiPot09kbIWF","outputId":"331df48e-7ae3-43c5-e46b-977e0462b62d"},"outputs":[{"output_type":"stream","name":"stdout","text":["app.py\t\t   evaluation_results_1_50.json  notebook.ipynb\n","Chatbot.ipynb\t   main.py\t\t\t __pycache__\n","dataset_loader.py  metrics.py\t\t\t requirements.txt\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"id":"Dgk3m025YSXI","metadata":{"executionInfo":{"elapsed":24372,"status":"ok","timestamp":1766089605503,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"},"user_tz":300},"id":"Dgk3m025YSXI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc022130-cf4b-4ed7-e2f5-f04056102d02"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"]}],"source":["import dataset_loader"]},{"cell_type":"code","execution_count":null,"id":"e0847318","metadata":{"id":"e0847318"},"outputs":[],"source":["# Import existing modules\n","from dataset_loader import load_squad_v2, prepare_contexts_for_rag\n","from metrics import evaluate_batch, evaluate_unanswerable"]},{"cell_type":"code","execution_count":null,"id":"31330318","metadata":{"id":"31330318"},"outputs":[],"source":["# CONFIGURATION\n","GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n","\n","EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n","LLM_MODEL = \"openai/gpt-oss-20b\"\n","CHUNK_SIZE = 1000\n","CHUNK_OVERLAP = 200\n","K_RETRIEVED = 3\n","MAX_SAMPLES = 50  # Set to None to use all samples"]},{"cell_type":"code","execution_count":null,"id":"1834Xx1zc9Fd","metadata":{"id":"1834Xx1zc9Fd"},"outputs":[],"source":["# RAG SETUP\n","def format_docs(docs):\n","    \"\"\"Format retrieved documents for context\"\"\"\n","    formatted = []\n","    for i, doc in enumerate(docs, 1):\n","        formatted.append(f\"[Source {i}]\\n{doc.page_content}\")\n","    return \"\\n\\n\".join(formatted)\n","\n","\n","def setup_rag_system(contexts, persist_directory=\"./chroma_db\"):\n","    \"\"\"Setup complete RAG system with retriever and LLM\"\"\"\n","\n","    # Embeddings\n","    embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n","\n","    # Check if index exists\n","    if os.path.exists(persist_directory) and os.listdir(persist_directory):\n","      print(\"Loading existing vector store from {persist_directory}...\")\n","\n","      # Load existing index\n","      vectorestore= Chroma(persist_directory= persist_directory, embedding_function=embedding_model)\n","      print(\"Loaded existing index!\")\n","    else:\n","      print(\"Creating new vector store and saving to {persist_directory}...\")\n","\n","    # Create vector store\n","    vectorstore = Chroma.from_documents(\n","        documents=contexts,\n","        embedding=embedding_model,\n","        persist_directory= persist_directory\n","    )\n","    print (\"Created and saved new index!\")\n","\n","    # Retriever\n","    retriever = vectorstore.as_retriever(\n","        search_type=\"similarity\",\n","        search_kwargs={\"k\": K_RETRIEVED}\n","    )\n","\n","    # LLM\n","    llm = ChatGroq(\n","        model=LLM_MODEL,\n","        groq_api_key=GROQ_API_KEY,\n","        temperature=0\n","    )\n","\n","    # Prompt\n","    prompt = ChatPromptTemplate.from_messages([\n","        (\n","            \"system\",\n","            \"You are a question-answering assistant. \"\n","            \"Answer the question using ONLY the provided context. \"\n","            \"If the answer cannot be found in the context, respond with 'I don't know' or 'The answer is not available in the provided context.'\"\n","        ),\n","        (\n","            \"human\",\n","            \"Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n","        )\n","    ])\n","\n","    # RAG Chain\n","    rag_chain = (\n","        {\n","            \"docs\": itemgetter(\"question\") | retriever,\n","            \"question\": itemgetter(\"question\"),\n","        }\n","        | RunnableLambda(lambda x: {\n","            \"question\": x[\"question\"],\n","            \"context\": format_docs(x[\"docs\"]),\n","        })\n","        | RunnableLambda(lambda x: {\n","            \"answer\": (\n","                prompt\n","                | llm\n","                | StrOutputParser()\n","            ).invoke({\n","                \"question\": x[\"question\"],\n","                \"context\": x[\"context\"],\n","            })\n","        })\n","    )\n","\n","    print(\"RAG system ready!\")\n","    return rag_chain"]},{"cell_type":"code","execution_count":null,"id":"R5NPF3ODdBDu","metadata":{"id":"R5NPF3ODdBDu"},"outputs":[],"source":["# EVALUATION\n","def evaluate_on_squad(rag_chain, examples, max_samples=MAX_SAMPLES):\n","    \"\"\"Evaluate RAG system \"\"\"\n","    if max_samples:\n","        examples = examples[:max_samples]\n","        print(f\"Using {max_samples} samples for evaluation\")\n","\n","    predictions = []\n","    ground_truths_list = []\n","    is_impossible_list = []\n","\n","    print(f\"\\nEvaluating on {len(examples)} examples...\")\n","\n","    for example in tqdm(examples, desc=\"Processing\"):\n","        try:\n","            # Get prediction from RAG system\n","            result = rag_chain.invoke({\"question\": example['question']})\n","            prediction = result[\"answer\"]\n","            predictions.append(prediction)\n","\n","            # Get ground truth answers\n","            ground_truths = example['answers']['text']\n","            ground_truths_list.append(ground_truths)\n","\n","            # Track if unanswerable\n","            is_impossible_list.append(example['is_impossible'])\n","        except Exception as e:\n","            print(f\"Error processing example {example['id']}: {e}\")\n","            predictions.append(\"\")\n","            ground_truths_list.append(example['answers']['text'])\n","            is_impossible_list.append(example['is_impossible'])\n","\n","    # Evaluate using metrics.py\n","    metrics = evaluate_batch(predictions, ground_truths_list)\n","    unanswerable_metrics = evaluate_unanswerable(predictions, is_impossible_list)\n","\n","    # Combine results\n","    results = {\n","        **metrics,\n","        **unanswerable_metrics,\n","        'total_samples': len(examples),\n","        'answerable_samples': sum(1 - x for x in is_impossible_list),\n","        'unanswerable_samples': sum(is_impossible_list)\n","    }\n","\n","    return results, predictions"]},{"cell_type":"code","execution_count":null,"id":"FqcWPYOrdM74","metadata":{"id":"FqcWPYOrdM74"},"outputs":[],"source":["def main():\n","    \"\"\"Main evaluation pipeline\"\"\"\n","    print(\"SQuAD v2 RAG Evaluation Pipeline\")\n","\n","    # Step 1: Load SQuAD v2 dataset (using your dataset_loader.py)\n","    print(\"\\nStep 1: Loading dataset...\")\n","    examples = load_squad_v2(split='validation')\n","    print(f\"Loaded {len(examples)} examples\")\n","\n","    # Step 2: Prepare contexts for RAG (using your dataset_loader.py)\n","    print(\"\\nStep 2: Preparing contexts...\")\n","    contexts = prepare_contexts_for_rag(\n","        examples,\n","        chunk_size=CHUNK_SIZE,\n","        chunk_overlap=CHUNK_OVERLAP\n","    )\n","    print(f\"Created {len(contexts)} document chunks\")\n","\n","    # Step 3: Setup RAG system\n","    print(\"\\nStep 3: Setting up RAG system...\")\n","    rag_chain = setup_rag_system(contexts)\n","\n","    # Step 4: Run evaluation\n","    print(\"\\nStep 4: Running evaluation...\")\n","    results, predictions = evaluate_on_squad(rag_chain, examples, MAX_SAMPLES)\n","\n","    # Step 5: Display results\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"EVALUATION RESULTS\")\n","    print(\"=\"*60)\n","    print(f\"F1 Score:              {results['f1']:.4f}\")\n","    print(f\"Exact Match (EM):      {results['em']:.4f}\")\n","    print(f\"Unanswerable Detection: {results['unanswerable_detection_accuracy']:.4f}\")\n","    print(f\"\\nDataset Statistics:\")\n","    print(f\"  Total Samples:       {results['total_samples']}\")\n","    print(f\"  Answerable:          {results['answerable_samples']}\")\n","    print(f\"  Unanswerable:        {results['unanswerable_samples']}\")\n","    print(\"=\"*60)\n","\n","    # Step 6: Save results\n","    output_file = 'evaluation_results.json'\n","    with open(output_file, 'w') as f:\n","        json.dump({\n","            'metrics': results,\n","            'sample_predictions': predictions[:20],  # Save first 20 for inspection\n","            'config': {\n","                'embedding_model': EMBEDDING_MODEL,\n","                'llm_model': LLM_MODEL,\n","                'chunk_size': CHUNK_SIZE,\n","                'chunk_overlap': CHUNK_OVERLAP,\n","                'k_retrieved': K_RETRIEVED,\n","                'max_samples': MAX_SAMPLES\n","            }\n","        }, f, indent=2)\n","\n","    print(f\"\\nResults saved to {output_file}\")\n","    print(\"Evaluation complete!\")\n"]},{"cell_type":"code","execution_count":null,"id":"12suVAtRdSQ2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12suVAtRdSQ2","outputId":"d06428d2-6889-4c60-d20e-862cda4fc7dc","executionInfo":{"status":"ok","timestamp":1766091339751,"user_tz":300,"elapsed":1241596,"user":{"displayName":"Harsuminder Gill","userId":"07866702323624119831"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["SQuAD v2 RAG Evaluation Pipeline\n","\n","Step 1: Loading dataset...\n","Loaded 11873 examples\n","\n","Step 2: Preparing contexts...\n","Created 14591 document chunks\n","\n","Step 3: Setting up RAG system...\n","Creating new vector store and saving to {persist_directory}...\n","Created and saved new index!\n","RAG system ready!\n","\n","Step 4: Running evaluation...\n","Using 50 samples for evaluation\n","\n","Evaluating on 50 examples...\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  66%|██████▌   | 33/50 [01:48<00:53,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 56dde27d9a695914005b9651: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 448. Please try again in 3m13.535999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 56dde27d9a695914005b9652: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 632. Please try again in 4m33.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  70%|███████   | 35/50 [01:48<00:24,  1.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3af11604f3c001a3fec63: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 481. Please try again in 3m27.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 5ad3af11604f3c001a3fec64: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 482. Please try again in 3m27.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  74%|███████▍  | 37/50 [01:49<00:10,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3af11604f3c001a3fec65: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 525. Please try again in 3m46.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 56dde2fa66d3e219004dad9b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 356. Please try again in 2m33.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  78%|███████▊  | 39/50 [01:49<00:05,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3c626604f3c001a3ff011: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 739. Please try again in 5m18.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 5ad3c626604f3c001a3ff012: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 356. Please try again in 2m32.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing:  80%|████████  | 40/50 [01:49<00:03,  2.68it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3c626604f3c001a3ff013: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 453. Please try again in 3m14.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  84%|████████▍ | 42/50 [01:49<00:02,  3.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 56de0f6a4396321400ee257f: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 618. Please try again in 4m25.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 5ad3dbc6604f3c001a3ff3e9: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 445. Please try again in 3m10.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  88%|████████▊ | 44/50 [01:49<00:01,  5.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3dbc6604f3c001a3ff3ea: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 610. Please try again in 4m22.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 5ad3dbc6604f3c001a3ff3eb: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 355. Please try again in 2m32.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  92%|█████████▏| 46/50 [01:50<00:00,  6.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3dbc6604f3c001a3ff3ec: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 614. Please try again in 4m23.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 56de0ffd4396321400ee258d: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 542. Please try again in 3m52.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing:  96%|█████████▌| 48/50 [01:50<00:00,  7.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 56de0ffd4396321400ee258e: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 543. Please try again in 3m52.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 56de0ffd4396321400ee258f: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 311. Please try again in 2m12.624s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"]},{"output_type":"stream","name":"stderr","text":["Processing: 100%|██████████| 50/50 [01:50<00:00,  2.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Error processing example 5ad3de8b604f3c001a3ff467: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 546. Please try again in 3m53.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Error processing example 5ad3de8b604f3c001a3ff468: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01k5stx7hwez8968pj3m4yf370` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 542. Please try again in 3m51.983999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","\n","============================================================\n","EVALUATION RESULTS\n","============================================================\n","F1 Score:              0.1123\n","Exact Match (EM):      0.3000\n","Unanswerable Detection: 0.4483\n","\n","Dataset Statistics:\n","  Total Samples:       50\n","  Answerable:          21\n","  Unanswerable:        29\n","============================================================\n","\n","Results saved to evaluation_results.json\n","Evaluation complete!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["main()"]},{"cell_type":"code","execution_count":null,"id":"St537fqcdVm8","metadata":{"id":"St537fqcdVm8"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"}},"nbformat":4,"nbformat_minor":5}